{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmzrDBmYrmDD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature**\n",
        "**Engineering**"
      ],
      "metadata": {
        "id": "f3EXLh6jrqe7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 1\n",
        "\n",
        "A parameter is a value that you pass into a function, method, or procedure to customize its behavior.\n",
        "\n",
        "In simple terms:\n",
        "\n",
        "A parameter is like a placeholder in a function definition.\n",
        "\n",
        "When you call the function, you provide a value (called an argument) for that parameter."
      ],
      "metadata": {
        "id": "XdZw7Ag5ruol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 2\n",
        "\n",
        "Correlation is a statistical measure that describes how two variables move in relation to each other. It tells you whether and how strongly pairs of variables are related.\n",
        "\n",
        "If two things tend to increase or decrease together ‚Üí positive correlation\n",
        "\n",
        "If one increases while the other decreases ‚Üí negative correlation\n",
        "\n",
        "If there's no consistent pattern ‚Üí no correlation\n",
        "\n",
        "What does negative correlation mean?\n",
        "A negative correlation means that as one variable goes up, the other tends to go down.\n",
        "\n",
        "Example:\n",
        "The more time you spend watching TV, the lower your grades might be.\n",
        "\n",
        "These two might have a negative correlation."
      ],
      "metadata": {
        "id": "wL0Nfxvqr9Zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 3\n",
        "\n",
        "Machine Learning (ML) is a branch of artificial intelligence (AI) that focuses on building systems that can learn from data and make decisions or predictions without being explicitly programmed for every task.\n",
        "\n",
        "Here are the key building blocks:\n",
        "\n",
        "Data üìä\n",
        "\n",
        "The fuel of machine learning.\n",
        "\n",
        "Can be images, text, numbers, clicks, etc.\n",
        "\n",
        "Quality and quantity of data affect model performance.\n",
        "\n",
        "Model üß©\n",
        "\n",
        "The algorithm or mathematical structure that makes predictions or decisions.\n",
        "\n",
        "Examples: Linear Regression, Decision Trees, Neural Networks.\n",
        "\n",
        "Features üîç\n",
        "\n",
        "The input variables used to make predictions.\n",
        "\n",
        "For example, in a housing price model: size, location, and number of rooms are features.\n",
        "\n",
        "Labels (for supervised learning) üè∑Ô∏è\n",
        "\n",
        "The correct output or answer that the model should learn to predict.\n",
        "\n",
        "E.g., in a spam filter: ‚Äúspam‚Äù or ‚Äúnot spam.‚Äù\n",
        "\n",
        "Training üèãÔ∏è\n",
        "\n",
        "The process of feeding data to the model so it can learn patterns.\n",
        "\n",
        "The model adjusts itself (its internal parameters) to reduce prediction errors."
      ],
      "metadata": {
        "id": "2jnxh-wIsOXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 4\n",
        "\n",
        "üí° What is Loss?\n",
        "The loss is a number that tells you how far off your model‚Äôs predictions are from the actual (true) values.\n",
        "\n",
        "It‚Äôs calculated using a loss function (like Mean Squared Error, Cross-Entropy, etc.).\n",
        "\n",
        "Lower loss = better predictions\n",
        "\n",
        "Higher loss = worse predictions\n",
        "\n",
        "\n",
        "üß™ How Does It Help Judge a Model?\n",
        "Here‚Äôs how the loss value helps:\n",
        "\n",
        "‚úÖ 1. Guides Training\n",
        "During training, the model adjusts itself to try to minimize the loss.\n",
        "\n",
        "Think of the loss as a \"score\" ‚Äî the lower, the better.\n",
        "\n",
        "‚úÖ 2. Early Warning Sign\n",
        "If the loss is high and not improving, the model may not be learning properly.\n",
        "\n",
        "If the loss is very low on training data but high on test data, it may be overfitting (memorizing instead of generalizing).\n",
        "\n",
        "‚úÖ 3. Comparing Models\n",
        "You can train multiple models and compare their loss values to pick the best one."
      ],
      "metadata": {
        "id": "LFv-bUSCyFwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 5\n",
        "\n",
        "Continuous Variables\n",
        "These are numerical values that can take any value within a range.\n",
        "\n",
        "You can measure them, and they often include decimals.\n",
        "\n",
        "Think of them as numbers that can be infinitely broken down.\n",
        "\n",
        "\n",
        "Categorical Variables\n",
        "These represent groups or categories.\n",
        "\n",
        "They usually have a limited number of distinct values.\n",
        "\n",
        "Can be text labels or coded as numbers."
      ],
      "metadata": {
        "id": "JLsgyp0FyX33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 6\n",
        "\n",
        "Machine Learning models don‚Äôt understand text or labels directly ‚Äî they need numbers. So, we need to convert categorical variables into numerical form in a smart way. That‚Äôs called encoding.\n",
        "\n",
        "1. Label Encoding\n",
        "Assigns a unique number to each category.\n",
        "\n",
        "2. One-Hot Encoding\n",
        "Creates new binary columns for each category (1 if present, 0 if not)\n",
        "\n",
        "\n",
        "3. Ordinal Encoding (for ordered categories)\n",
        "Like Label Encoding, but used when order matters\n",
        "\n",
        "4. Target Encoding (Mean Encoding)\n",
        "Replace each category with the average of the target variable for that category"
      ],
      "metadata": {
        "id": "kWGmt7Y1y2oz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 7\n",
        "\n",
        "Training means feeding data to a machine learning model so it can learn patterns.\n",
        "\n",
        "This is where the model adjusts itself to minimize errors (reduce the loss).\n",
        "\n",
        "Think of it like teaching a student using a study guide or practice problems.\n",
        "\n",
        "What is Testing a Dataset?\n",
        "Testing is how you evaluate the model's performance on new, unseen data.\n",
        "\n",
        "The goal is to check if the model generalizes well, not just memorized the training data.\n",
        "\n",
        "It's like giving the student a final exam after they've studied."
      ],
      "metadata": {
        "id": "d8no8rpe3VHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 8\n",
        "\n",
        "sklearn.preprocessing is a module in Scikit-learn (a popular Python ML library) that contains tools to prepare or transform your data before feeding it into a machine learning model.\n",
        "\n",
        "Think of it as the \"data cleaning and setup\" toolkit ‚Äî it helps make your data suitable for training."
      ],
      "metadata": {
        "id": "yf6hx-MB3vzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 9\n",
        "\n",
        "A test set is a portion of your dataset that you set aside to evaluate your machine learning model after it has been trained.\n",
        "\n",
        "Think of it as the final exam for your model."
      ],
      "metadata": {
        "id": "7pta2R_333_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 10\n",
        "\n",
        "We usually use Scikit-learn‚Äôs train_test_split() function. It splits your dataset into training and test sets.\n",
        "\n",
        "2. How to Approach a Machine Learning Problem\n",
        "\n",
        "\n",
        "\n",
        "Step 1: Understand the Problem\n",
        "What are you trying to predict?\n",
        "\n",
        "Is it classification (label) or regression (number)?\n",
        "\n",
        "What does success look like (accuracy, RMSE, etc.)?\n",
        "\n",
        "\n",
        "Step 2: Collect and Explore the Data\n",
        "Load your dataset (CSV, SQL, etc.)\n",
        "\n",
        "Look at summary stats: df.info(), df.describe()\n",
        "\n",
        "Visualize relationships with plots (e.g. seaborn, matplotlib)\n",
        "\n",
        " Step 3: Preprocess the Data\n",
        "Handle missing values\n",
        "\n",
        "Encode categorical variables\n",
        "\n",
        "Scale/normalize features\n",
        "\n",
        "Split into training and test sets\n",
        "\n",
        "Step 4: Choose a Model\n",
        "Classification? Try LogisticRegression, RandomForestClassifier, etc.\n",
        "\n",
        "Regression? Try LinearRegression, DecisionTreeRegressor, etc.\n",
        "\n",
        "Step 5: Train the Model\n",
        "\n",
        " Step 6: Evaluate the Model\n",
        "\n",
        " Step 7: Tune the Model\n",
        "Try different algorithms\n",
        "\n",
        "Use cross-validation\n",
        "\n",
        "Optimize hyperparameters (GridSearchCV, RandomizedSearchCV)\n",
        "\n",
        "Step 8: Deploy / Use the Model\n",
        "Use it to make real predictions\n",
        "\n",
        "Possibly export the model (joblib, pickle) for deployment"
      ],
      "metadata": {
        "id": "f6o-ql6j3_my"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 11\n",
        "\n",
        "Why Perform EDA Before Model Fitting?\n",
        "1. Understanding the Data:\n",
        "\n",
        "Before diving into machine learning, you need to understand the dataset you're working with. This means knowing:\n",
        "\n",
        "What each feature represents\n",
        "\n",
        "The types of variables (numerical or categorical)\n",
        "\n",
        "The relationships between variables (correlations, distributions)\n",
        "\n",
        "\n",
        "2. Identifying Data Issues:\n",
        "\n",
        "Missing Values: Incomplete data can hurt model performance. EDA helps spot missing values so you can handle them (e.g., imputation, removal).\n",
        "\n",
        "Outliers: Extreme values that don't fit the data pattern can skew your model. EDA helps you identify these outliers early.\n",
        "\n",
        "Incorrect Data Types: Sometimes, data may be stored incorrectly (e.g., numbers as strings). EDA allows you to catch these issues before training.\n",
        "\n",
        "3. Visualizing Relationships Between Features:\n",
        "\n",
        "EDA lets you visualize correlations between features and the target variable. For example, with a scatter plot or correlation matrix, you can see which features are more closely related to your target.\n",
        "\n",
        "Example: If you're predicting house prices, you might see that the \"square footage\" of the house is highly correlated with the price. This can help you decide which features are most important for model fitting.\n",
        "\n",
        ". Feature Engineering and Transformation:\n",
        "\n",
        "EDA can suggest new features or help you transform existing ones to improve model performance.\n",
        "\n",
        "Example: If your data includes a \"date\" column, you might extract year, month, or day-of-week to create additional features.\n",
        "\n",
        "EDA also shows you when features need to be scaled or normalized, especially if you're using distance-based models (like KNN or SVM).\n",
        "\n"
      ],
      "metadata": {
        "id": "KCIzmnjA78Jb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 12\n",
        "\n",
        "Correlation is a statistical measure that describes the relationship between two or more variables. In simpler terms, it tells us how strongly two variables are related and in which direction."
      ],
      "metadata": {
        "id": "ZMjbr83oDaNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 13\n",
        "\n",
        "Negative correlation means that as one variable increases, the other variable tends to decrease. In other words, there is an inverse relationship between the two variables.\n",
        "\n"
      ],
      "metadata": {
        "id": "npQX9qQxFwl2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 14\n",
        "\n",
        "o find the correlation between variables in Python, we typically use pandas or NumPy. Here's how you can do that:\n",
        "\n",
        "\n",
        "Using Pandas: .corr() Method\n",
        "The most common way to find the correlation between variables is by using the pandas library, which provides a simple .corr() method. This method calculates the Pearson correlation coefficient, which is the most widely used type of correlation.\n",
        "\n"
      ],
      "metadata": {
        "id": "Rwl_1aB_F4zV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 15\n",
        "\n",
        "Causation refers to a relationship where one event or variable directly causes another event or variable to change. In other words, A causes B means that the change in A will lead to a change in B. This is a direct influence, not just an association.\n",
        "\n",
        "\n",
        "Difference Between Correlation and Causation:\n",
        "Correlation: It indicates that two variables are related (they move together), but it doesn‚Äôt necessarily mean that one causes the other.\n",
        "\n",
        "Causation: It means that one variable directly causes the change in another. It establishes a cause-and-effect relationship.\n",
        "\n"
      ],
      "metadata": {
        "id": "DeSn58DIGSec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 16\n",
        "\n",
        "In machine learning and deep learning, an optimizer is an algorithm used to minimize or maximize the loss function during training. The loss function (or cost function) measures how well or poorly the model's predictions match the true values (labels). The optimizer's job is to adjust the model‚Äôs parameters (weights and biases) in a way that reduces the loss, thereby improving the model‚Äôs accuracy.\n",
        "\n",
        "Different Types of Optimizers:\n",
        "There are several types of optimizers commonly used in machine learning and deep learning. Below are the most popular ones, along with explanations and examples.\n",
        "\n",
        "1. Stochastic Gradient Descent (SGD)\n",
        "SGD is the most basic and widely used optimizer in machine learning. It updates the model‚Äôs parameters based on the gradient of the loss function calculated from one data point at a time (as opposed to the full dataset).\n",
        "\n"
      ],
      "metadata": {
        "id": "Hleq3EO-Guhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# Example of using SGD with a classification task\n",
        "model = SGDClassifier(loss=\"hinge\", max_iter=1000)\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "xMf2syCwHH9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Momentum\n",
        "Momentum is an extension of SGD that helps accelerate the optimization process by adding a fraction of the previous update to the current update. This helps to overcome the problem of getting stuck in local minima and speeds up the training.\n",
        "\n"
      ],
      "metadata": {
        "id": "vOLO4ztIHKAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD\n",
        "\n",
        "# Example of using SGD with momentum in Keras\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "juS9tSSwHPuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 17\n",
        "\n",
        "**sklearn.linear_model** is a module in scikit-learn (a popular Python machine learning library) that provides a set of linear models for regression and classification tasks. These models are designed to establish a linear relationship between the input features (independent variables) and the target variable (dependent variable).\n",
        "\n",
        "Linear models assume that the relationship between the features and the target can be approximated as a linear equation."
      ],
      "metadata": {
        "id": "SzgOSUHYHShm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 18\n",
        "\n",
        "It trains the model by adjusting the model's internal parameters.\n",
        "\n",
        "It optimizes the model using the given data to minimize the loss function, which measures how well the model's predictions match the actual target values.\n",
        "\n",
        "After calling fit(), the model will be ready to make predictions using the trained parameters.\n",
        "\n",
        "Arguments for model.fit()\n",
        "The typical arguments that are passed to model.fit() depend on the type of model (e.g., regression, classification). Here are the most common arguments:\n",
        "\n",
        "1. X (Required):\n",
        "This is the input data or features.\n",
        "\n",
        "It is usually a 2D array or matrix where rows represent samples (individual data points) and columns represent features (variables).\n",
        "\n",
        "Shape: (n_samples, n_features) where:\n",
        "\n",
        "n_samples is the number of data points.\n",
        "\n",
        "n_features is the number of features (input variables).\n",
        "\n",
        "2. y (Required):\n",
        "This is the target data or labels (the actual values you're trying to predict).\n",
        "\n",
        "For regression tasks, this is a continuous variable (real numbers).\n",
        "\n",
        "For classification tasks, this is usually a discrete value representing the class label (e.g., 0 or 1).\n",
        "\n",
        "Shape: (n_samples,) where n_samples is the number of data points."
      ],
      "metadata": {
        "id": "I2L4LCPYJJzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 19\n",
        "\n",
        "model.predict() is a method used in many machine learning frameworks (like TensorFlow/Keras, scikit-learn, etc.) to generate predictions from a trained model.\n",
        "\n",
        "What it does:\n",
        "It takes input data and outputs the predicted result(s) based on the model's learned parameters.\n",
        "\n",
        "It is used after the model has been trained, typically with model.fit() or similar methods.\n",
        "\n",
        "In Keras / TensorFlow:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "predictions = model.predict(x)\n",
        "Arguments:\n",
        "x: The input data. This can be:\n",
        "\n",
        "A NumPy array\n",
        "\n",
        "A list of arrays (if the model has multiple inputs)\n",
        "\n",
        "A TensorFlow tensor\n",
        "\n",
        "A tf.data Dataset\n",
        "\n",
        "Or even a generator\n",
        "\n",
        "Optional arguments:\n",
        "\n",
        "batch_size: Number of samples per batch (defaults to what was used in training or inferred).\n",
        "\n",
        "verbose: 0 (silent), 1 (progress bar), or 2 (one line per epoch).\n",
        "\n"
      ],
      "metadata": {
        "id": "uQb4t2lEK6-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 20\n",
        "\n",
        "Definition:\n",
        "A continuous variable is a numeric variable that can take any value within a range ‚Äî including fractions and decimals.\n",
        "\n",
        "Examples:\n",
        "Height (e.g., 5.7 feet)\n",
        "\n",
        "Temperature (e.g., 98.6¬∞F)\n",
        "\n",
        "Income (e.g., $45,000.75)\n",
        "\n",
        "Age (in years, with decimal points like 24.3)\n",
        "\n",
        "\n",
        "\n",
        "Definition:\n",
        "A categorical variable is one that has a limited number of distinct groups or categories.\n",
        "\n",
        "Examples:\n",
        "Gender (Male, Female, Other)\n",
        "\n",
        "Country (USA, Canada, Mexico)\n",
        "\n",
        "Product Type (Phone, Laptop, Tablet)\n",
        "\n",
        "Yes/No responses (Binary categories)"
      ],
      "metadata": {
        "id": "ypEiJV39FBQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 21\n",
        "\n",
        "What is Feature Scaling?\n",
        "Feature scaling adjusts the range or distribution of feature values so that:\n",
        "\n",
        "No single feature dominates due to its scale (like \"Income in dollars\" vs. \"Age in years\").\n",
        "\n",
        "Models that rely on distance or gradient descent perform more effectively.\n",
        "\n",
        "\n",
        "1. Min-Max Scaling (Normalization)\n",
        "\n",
        "X_scaled = (X - X.min()) / (X.max() - X.min())\n",
        "\n",
        "\n",
        "2. Standardization (Z-score Scaling)\n",
        "\n",
        "X_scaled = (X - X.mean()) / X.std()\n",
        "\n",
        "\n",
        "3. Robust Scaling\n",
        "\n",
        "In sklearn: RobustScaler()\n",
        "\n"
      ],
      "metadata": {
        "id": "OvF2pJ4YFSpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 22\n",
        "\n",
        "1. Min-Max Scaling (Normalization)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "X = np.array([[1, 2], [2, 4], [3, 6]])\n",
        "\n",
        "# Create scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n",
        "\n",
        "\n",
        "\n",
        "2. Standardization (Z-score Scaling)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n",
        "\n",
        "\n",
        " 3. Robust Scaling\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n",
        "\n",
        "\n",
        " 4. Using Pandas + Scikit-learn\n",
        "\n",
        " import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'height': [150, 160, 170],\n",
        "    'weight': [50, 65, 80]\n",
        "})\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_array = scaler.fit_transform(df)\n",
        "\n",
        "scaled_df = pd.DataFrame(scaled_array, columns=df.columns)\n",
        "print(scaled_df)\n"
      ],
      "metadata": {
        "id": "NW_gCH4JF05F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 23\n",
        "\n",
        "sklearn.preprocessing is a module in Scikit-learn that provides tools to transform and scale your data ‚Äî making it suitable for machine learning models.\n",
        "\n",
        "Purpose of sklearn.preprocessing:\n",
        "It helps you:\n",
        "\n",
        "Scale features (e.g., normalization, standardization)\n",
        "\n",
        "Encode categorical data\n",
        "\n",
        "Generate polynomial features\n",
        "\n",
        "Binarize or discretize data\n"
      ],
      "metadata": {
        "id": "2FM--Sm5GkwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 24\n",
        "\n",
        "Splitting your data into training and testing sets is a key step in building machine learning models ‚Äî it helps you evaluate how well your model generalizes to unseen data.\n",
        "\n",
        "train_test_split() from sklearn.model_selection\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "OHgkOEhdJT9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 25\n",
        "\n",
        "Data encoding is the process of converting categorical data (text or labels) into a numerical format, so that machine learning models can understand and work with it.\n",
        "\n",
        "Since most ML algorithms can‚Äôt work directly with text, we need to encode these values into numbers.\n",
        "\n",
        "Types of Data Encoding:\n",
        "1. Label Encoding\n",
        "\n",
        "2. One-Hot Encoding\n",
        "\n",
        "3. Ordinal Encoding"
      ],
      "metadata": {
        "id": "oWoLVdMsJxDr"
      }
    }
  ]
}